---
title: 第三章-存储系统
date: 2022-07-30
order: 3
toc: true
headerDepth: 2
---

## 3.1 [存储系统基本概念](https://blog.csdn.net/qq_43896405/article/details/119785783)

### 1.存储器的层次化结构

![](https://img1.imgtp.com/2022/07/29/E0axxyRX.svg)

- 主存和Cache之间的数据调动是由硬件自动完成的，对所有程序员透明
- 主存和辅存之间的数据调动由硬件和操作系统共同完成，对应用程序员透明
- 辅存中的数据要调入主存后才被CPU访问

![](https://img1.imgtp.com/2022/07/29/64sfGZu6.svg)

有的教材把安装在电脑内部的磁盘称为"辅存", 把U盘, 光盘等称为"外存". 也有的教材把磁盘, U盘, 光盘等统称为"辅存"或者"外存"

- 主存-辅存: 实现虚拟操作系统, 解决了主存容量不够的问题
- Cache-主存: 解决了主存与CPU速度不匹配的问题

### 2.存储器的分类

#### 按照层次

- 高速缓存(Cache)
- 主存储器(主存, 内存)
- 辅助存储器(辅存, 外存)

#### 存储介质

- 半导体存储器(主存, Cache)
- 磁表面存储器(磁盘, 磁带)
- 光存储器(光盘, DVD)

#### 存取方式

- 随机存取存储器(Random Access Memory, RAM): 读写任何一个存储单元所需的时间都相同, 与存储单元所在的物理位置无关
- 顺序存取存储器(Sequential Access Memory, SAM): 读写一个存储单元所需的时间取决于存储单元所在的物理位置
- 直接存取存储器(Direct Access Memory, DAM): 既有随机存取特性, 也有顺序存储的特性. 先直接选取信息所在的区域, 然后按照顺序方式存取
- 相联存储器(Associative Memory), 即可以按内容访问的存储器(Content Addressed Memory, CAM), 可以按照内容检索到存储位置进行读写, "快表"就是一种相联存储器

> 串行访问存储器: 读写某个存储单元所需的时间和存储单元的物理位置有关, 上述SAM和DAM就是串行访问存储器

> RAM, SAM和DAM是按照地址来访问, CAM是按照内容来访问

#### 信息的可更改性

- 读写存储器(Read/Write Memory) -- 既可读, 也可写(如: 磁盘, 内存, Cache)
- 只读存储器(Read Only Memory) -- 只能读, 不能写(如: 实体音乐专辑通常采用的CD-ROM, 实体电影中采用的蓝光光碟, BIOS通常写在ROM中)

#### 信息的可保存性

- 断电后, 存储信息消失的存储器 -- 易失性存储器(主存, Cache)
- 断电后, 存储信息依然保持的存储器 -- 非易失性存储器(磁盘, 光盘)

- 信息读出后, 原存储信息被破坏 -- 破坏性读出(如DRAM芯片, 读出数据后要进行重写)
- 信息读出后, 原存储信息不会被破坏 -- 非破坏性读出(如SRAM芯片, 磁盘, 光盘)

### 3.存储器的性能指标

- 存储容量: 存储字数*字长
- 单位成本: 每位价格=总成本/总容量
- 存储速度: 数据传输率=数据的宽度/存储周期

1. 存储时间($T_a$): 存取时间指的是从启动一次存储器操作到完成该操作所经历的时间, 分为读出时间和写入时间
2. 存取周期($T_m$): 存取周期又称为读写周期或者访问周期, 它是指存储器进行一次完整的读写操作所需要的全部时间, 即连续两次独立地访问存储器操作(读或写操作)之间所需要的最小时间间隔
3. 主存带宽($B_m$): 主存带宽又称为数据传输率, 表示每秒从主存进出信息的最大数量, 单位为字/秒, 字节/秒或者位/秒

## 3.2 主存储器的基本组成

### 1.基本的半导体元件及原理

![](https://img1.imgtp.com/2022/07/29/OjWzqbfg.svg)

一个内存颗粒上的金属引脚:
1. 地址线
2. 数据线
3. 读写控制线(1个或2个)
4. 片选线(1个)
5. 供电引脚
6. 接地引脚

> 常见的描述: 
> <br> 8K\*8位, 即2^13\*8bit
> <br> 8K\*1位, 即2^13\*1bit
> <br> 64K\*16位, 即2^16\*16bit

### 2.寻址

总容量为1KB(字长4B):

- 按照字节寻址: 1K个单元, 每个单元1B
- 按字寻址: 256个单元, 每个单元4B
- 按半字寻址: 512个单元, 每个单元2B
- 按双字寻址: 128个单元, 每个单元8B

## 3.3 SRAM&DRAM

### 1.栅极电容 V.S. 双稳态触发器

| 类型特点           | SRAM(静态RAM) | DRAM(动态RAM)            |
| ------------------ | ------------- | ------------------------ |
| 存储信息           | 触发器        | 电容                     |
| 破坏性读出         | 非            | 是                       |
| 读出后需要重写?    | 不用          | 需要                     |
| 运行速度           | 快            | 慢                       |
| 集成度             | 低            | 高                       |
| 发热量             | 大            | 小                       |
| 存储成本           | 高            | 低                       |
| 易失/非易失存储器? | 易失          | 易失                     |
| 需要刷新?          | 不需要        | 需要(分散, 集中, 异步)   |
| 送行列地址         | 同时送        | 分两次送(地址线复用技术) |
| 用途               | 常用作Cache   | 常用作主存               |

#### 栅极电容(DRAM存储元)

![](https://img1.imgtp.com/2022/07/29/JMULozM1.png)

- 读出1: MOS管接通, 电容放电, 数据线上产生电流
- 读出0: MOS管接通后, 数据线上无电流

电容放电信息被破坏, 是破坏性读出, 读出后应有重写操作, 也成为"再生", 读写速度更慢

每个存储单元制造成本更低, 集成度更高, 功耗低

#### 双稳态触发器(SRAM存储元)

![](https://img1.imgtp.com/2022/07/29/As4U9VxO.png)

双稳态:
<br> 1: A高B低
<br> 0: A低B高

读出数据, 触发器状态保持稳定, 是非破坏性读出, 无需重写, 读写速度更快

每个存储单元制造成本更高, 集成度低, 功耗大

### 2.DRAM的刷新

1. 多久刷新一次? 刷新周期: 一般为2ms
2. 刷新方式
   - 集中刷新：在一个刷新周期内，利用一段固定的时间，依次对所有行逐一再生（死时间）
   - 分散刷新：把对每行的刷新分散到各个工作周期中，工作周期前半部分读写，后半部分刷新
     - 增加了系统的存取周期，降低了整机的速度
   - 异步刷新：将刷新周期除以行数，得到两次刷新操作之间的时间间隔，每隔时间间隔进行一次刷新操作
3. 注
    - 刷新对CPU是透明的，刷新不依赖于外部的访问
    - 刷新单位是行，由芯片内部自行生成行地址
    - 刷新不需要选片，所有芯片同时刷新
<!-- 3. 每次刷新多少存储单元? 以行为单位, 每次刷新一行存储单元
1. 如何刷新? 有硬件的支持, 读出一行的信息后重新写入, 占用1个读/写周期
2. 在什么时刻刷新?  -->

#### 为什么要用行列地址?

> 地址为00000000, 前半部分(0000)作为行地址送给行地址译码器, 后半部分(0000)作为列地址送给列地址译码器. 如果采用非矩阵模型, 则需要2^8=256根选通线, 如果采用矩阵模型, 则需要2^4+2^4根选通线(排列成16*16的矩阵)

#### 在什么时刻刷新?

> 假设DRAM内部结构排列成128*128的形式, 读/写周期0.5us, 2ms共2ms/0.5us=4000个周期

##### 分散刷新

> 每次读写完都刷新一行, 系统的存取周期变为1us, 前0.5us时间属于正常读写, 后0.5us时间属于刷新某行

##### 集中刷新

> 2ms内集中安排时间全部刷新, 系统的存取周期还是0.5us, 有一段使时间专门用于刷新, 无法访问存储器, 称为访存"死区"
> <br> 3872个周期(1936us)用于读写, 128个周期(64us)用于刷新

##### 异步刷新

> 2ms内每行刷新1次即可, 2ms内需要产生128次的刷新请求, 每隔2ms/128=15.6us一次, 每15.6us内有0.5us的"死时间"

### DRAM的地址线复用技术

![](https://img1.imgtp.com/2022/10/18/MSiOlTBu.png)

同时传送行地址和列地址会导致地址线很多(n条), 故采用地址线复用技术, 采用n/2条地址线, 先将行地址送入行地址缓冲器, 再将列地址送入列地址缓冲器, 最后分别送到行地址译码器和列地址译码器. 会导致地址线, 地址线的引脚减半

## 3.4 read only memory ROM

### 1.了解各种ROM

#### MROM(Mask Read-Only Memory)

掩模式只读存储器: 厂家按照客户需求, 在芯片生产过程中直接写入信息, 之后任何人不得重写(只能读出), 可靠性高, 灵活性差, 生产周期长, 知识和批量定制

#### PROM(Programmable Read-Only Memory)

可编程只读存储器: 用户可用专门的额PROM写入器写入信息, 写**一次**之后就不可更改

#### EPROM(Erasable Programmable Read-Only Memory)

允许用户写入信息, 之后采用某种方法擦除数据, 可进行多次重写

- UVEPROM(ultraviolet rays): 用紫外线照射8~20分钟, 擦除所有的信息
- EEPROM(第一个E是Electrically): 可用"电擦除"的方式, 擦除特定的字

#### Flash Memory

闪速存储器: 在EEPROM的基础上发展而来, 断电后也能保存信息, 且可进行多次快速的擦除和重写. 由于闪存需要先擦除再写入, 故闪存的"写"的速度要比"读"的速度慢. (U盘, SD卡就是闪存)

#### SSD(Solid State Drives)

固态硬盘: 由控制单元+存储单元(Flash芯片)组成, 与闪速存储器的核心区别在于控制单元不一样, 但存储介质都类似, 可进行多次快速地擦除和重写你, SSD速度快, 功耗低, 价格高. 目前个人电脑常常使用SSD取代传统的机械硬盘(手机辅存也使用Flash芯片, 但是相比SSD使用的芯片集成度高, 功耗低, 价格贵)

### 2.计算机内的重要ROM

![](https://img1.imgtp.com/2022/07/29/nYtjxKcC.svg)

主板上的BIOS芯片就是ROM, 通常我们所说的内存条就是"主存", 但事实上, 主板上的ROM芯片也是"主存"的一部分, 逻辑上, 主存由RAM+ROM组成, 且两者常统一编址

## 3.5 主存储器与CPU的连接

### 1.增加主存的字长-位扩展

![](https://img1.imgtp.com/2022/07/29/8iNs7gjP.png)

### 2.增加主存的存储字数-字扩展

![](https://img1.imgtp.com/2022/07/29/b1T25mbi.png)

### 3.增加主存的存储字数-字位扩展

![](https://img1.imgtp.com/2022/07/29/I6IG9oJY.png)

## 双口RAM&多模块存储器

### 存取周期

![](https://img1.imgtp.com/2022/07/29/Al2vJCa2.svg)

存取周期: 可以连续读/写的最短时间间隔

DRAM芯片的恢复时间比较长, 有可能是存取时间的几倍(SRAM的恢复时间较短), 如DRAM的存取时间为r, 存取周期为T, 则T=4r 

产生的问题: 
1. 多核CPU要访问内存, 怎么办? 
2. CPU的读写速度比主存快很多, 主存恢复时间太长怎么办?

### 双端口RAM

需要有两组完全独立的数据线, 地址线, 控制线. CPU, RAM中也要有更加复杂的控制电路

![](https://img1.imgtp.com/2022/07/29/GgcV5Awh.png)

两个端口对同一主存操作有以下四种情况:
1. 两个端口同时对不同的地址单元存取数据(可以实现)
2. 两个端口同时对同一地址单元读出数据(可以实现)
3. 两个端口同时对同一地址单元写入数据(写入错误)
4. 两个端口同时对同一地址单元, 一个写入数据, 另一个读出数据(读出错误)

解决方法: 置"忙"信号为0, 由判断逻辑决定暂时关闭一个端口(即被延时), 未被关闭的端口正常访问, 被关闭的端口延长一个很短的时间段后再访问

作用: 优化多核CPU访问一根内存条的速度

### 多体并行存储器

> 每个存储体存取周期为T, 存取时间为r, 假设T=4r
> <br> 连续访问: 00000, 00001, 00010, 00011, 00100

为什么要考虑"连续访问"的情况?
<br> 因为在实际应用中, 有很多数据是连续的存储在主存中的, 比如说数组, 程序的指令都是连续的存储在主存中的

#### 高位交叉编址

![](https://img1.imgtp.com/2022/07/29/T86mJbBJ.png)

> 连续取n个存储字
> <br> 耗时nT, 耗时5T

#### 低位交叉编址

宏观上读写一个字的时间接近r

![](https://img1.imgtp.com/2022/07/29/k9nNCcCD.png)

> 耗时T+4r=2T
> <br> 连续存n个存储字
> <br> 耗时T+(n-1)r

### 应该取第几个"体"?

采用"流水线"的方式并行存取(宏观上并行, 微观上串行). 宏观上, 一个存储周期内, m体交叉存储器可以提供的数据量为单个模块的m倍

存取周期为T, 存取时间(总线传输周期)为r, 为了使流水线不间断, 应保证模块的数量m≥T/r:
1. 如果m<T/r, 则会导致CPU需要等待
2. 如果m>T/r, 则会导致芯片闲置

### 多模块存储器

#### 多体并行存储器

每个模块都有相同的容量和存取速度
<br> 各模块都有独立的读写控制电路, 地址寄存器和数据寄存器. 它们既能并行工作, 又能交叉工作.

#### 单体多字存储器

每个存储单元存储m个字
<br> 总线宽度也为m个字
<br> 一次并行读出m个字
<br> 每次只能同时取m个字, 不能单独取其中某个字, 指令和数据在主存中必须是连续存放的

### 内存条

单纯的扩容: 实现高位交叉的多体存储器
双通道: 实现低位交叉的多体存储器

买内存条时, 可挑选相同主频(主频反映的是存取周期, 如果主频不一样, 可能会导致高主频的内存降频), 相同容量(高容量的部分会按单通道处理)的两根来组成双通道

## Cache的基本概念和原理

### 存储系统存在的问题

1. 经过多模块存储器优化后, 存储器的速度和CPU的速度差距依然很大
2. 可以采用更加高速的存储单元设计, 但是会导致存储器的价格上升, 容量下降
3. 故基于程序的局部性原理, 可以增加一个Cache层, 改善"Cache-主存"的层次

### Cache的工作原理

![](https://img1.imgtp.com/2022/07/29/KBmyndLC.svg)

实际上, Cache被集成在CPU内部, Cache用SRAM实现, 速度快, 成本高

### 局部性原理

- 空间局部性: 在最近的未来要用到的信息(指令和数据), 很可能与现在正在使用的信息在存储空间上是邻近的(比如说数组元素, 顺序执行的指令代码)
- 时间局部性: 在最近的未来要用到的信息, 很可能是现在正在使用的信息(循环结构的指令代码)

基于局部性原理, 不难想到, 可以把CPU当前访问地址"周围"的部分数据存放到Cache中. 程序B按照"列优先"访问二维数组, 空间局部性更差

### 性能分析

设tc为访问一次Cache所需要的时间, tm为访问一次主存所需要的时间

- 命中率H: CPU欲访问的信息已在Cache中的比率
- 缺失(未命中)率: M=1-H

Cache-主存系统的平均访问时间t为: t=Htc+(1-H)(tc+tm)(先访问Cache, 若Cache未命中再访问主存); 或者t=Htc+(1-H)tm(同时访问Cache和主存, 若Cache命中则立即停止访问主存)

> 假设Cache的速度是主存的5倍, 且Cache的命中率为95%, 则采用Cache后, 存储器性能提高多少(设Cache和主存同时被访问, 若Cache命中则中断访问主存)?
> <br> 设Cache的存取周期为t, 则主存的存取周期为5t
> <br> 若Cache和主存同时访问, 命中时访问时间为t, 未命中时访问时间为5t, 平均访问时间为0.95*t+0.05*5t=1.2t, 故性能为原来的5t/1.2t≈4.17倍
> <br> 若先访问Cache再访问主存, 命中时访问时间为t, 未命中时访问时间为t+5t, 平均访问时间为0.95*t+0.05*6t=1.25t, 故性能为原来的5t/1.25t=4倍

### 有待解决的问题

#### 问题1

基于局部性原理, 不难想到, 可以把CPU目前访问的地址"周围"的部分数据放到Cache中. 如何界定"周围"?

将主存的存储空间"分块", 如:每1KB为一块, 主存和Cache之间以"块"为单位进行数据交换

![](https://img1.imgtp.com/2022/07/29/RmH39vFr.svg)

主存的地址共22位: 块号12位, 块内地址10位, 4M=2^22, 1K=2^10, 整个主存被分为2^12=4096块

#### 问题2

如何区分Cache和主存的数据块对应关系? - Cache和主存的映射方式

#### 问题3

Cache很小, 主存很大, 如果Cache满了怎么办? - 替换算法

#### 问题4

CPU修改了Cache中的数据副本, 如何确保主存中数据母本的一致性? - Cache写策略

## Cache和主存的映射方式

### 全相联映射(随意放)

> 假设某个计算机的主存地址空间大小为256MB, 按照字节编址, 其数据Cache有8个Cache行, 行长为64B
> <br> Cache的总大小为512B, 256M=2^28, 主存的地址共28位, 2^28/2^6=2^22, 主存块号共22位, 块内地址共6位
> CPU访问主存地址1...1101 001110:
> 1. 主存地址的前22位, 对比Cache中所有块的标记
> 2. 若标记匹配且有效位=1, 则Cache命中, 访问块内地址为001110的单元
> 3. 若未命中或有效位=0, 则正常访问主存

![](https://img1.imgtp.com/2022/07/29/FcPZOXFP.png)

### 直接映射(只能放固定位置)

主存块在Cache中的位置=主存块号%Cache总块数, 缺点是其他地方有空闲Cache块, 但是8号主存块不能使用

主存块号%(2^3), 相当于留下最后三位二进制数(若Cache总块数=2^n, 则主存块号末位n位直接反映它在Cache中的位置), 将主存块号的其余作为标记即可

> CPU访问主存地址0...01000 001110: 
> 1. 根据主存块号的后3位确定Cache行
> 2. 若主存块号的前19位与Cache标记匹配且有效位=1, 则Cache命中, 访问块内地址为001110的单元
> 3. 若未命中或者有效位=0, 则正常访问主存

### 组相联映射(可放到特定分组)

所属分组=主存块号%分组数

主存块号%2^2, 相当于留下最后两位

> CPU访问主存地址1...1101001110: 
> 1. 根据主存块号的后2位确定所属分组号
> 2. 若主存块号的前20位与分组内的某个标记匹配且有效位=1, 则Cache命中, 访问块内地址为001110的单元
> 3. 若未命中或者有效位=0, 则正常访问

## Cache替换算法

### 随机算法(RAND)

随机算法(RAND, Random) -- 若Cache已满, 则随机选择一块替换

> 设总共有4个Cache块, 初始整个Cache为空. 采用全相联映射, 依次访问主存块1,2,3,4,1,2,5,1,2,3,4,5
> |访问主存块|1|2|3|4|1|2|5|1|2|3|4|5|
> |-|-|-|-|-|-|-|-|-|-|-|-|-|
> |Cache #0|1|1|1|1|1|1|1|1|1|1|4|4|
> |Cache #1||2|2|2|2|2|2|2|2|2|2|2|
> |Cache #2|||3|3|3|3|5|5|5|5|5|5|
> |Cache #3||||4|4|4|4|4|4|3|3|3|
> |Cache命中?|否|否|否|否|是|是|否|是|是|否|否|是|
> |Cache替换?|否|否|否|否|否|否|是|否|否|是|是|否|

随机算法 -- 实现简单, 但完全没考虑局部性原理, 命中率低, 实际效果很不稳定

### 先进先出算法(FIFO)

先进先出算法(FIFO, First In First Out) -- 若Cache已满, 则替换最先被调入Cache的块

> 设总共有4个Cache块, 初始整个Cache为空. 采用全相联映射, 依次访问主存块1,2,3,4,1,2,5,1,2,3,4,5
> |访问主存块|1|2|3|4|1|2|5|1|2|3|4|5|
> |-|-|-|-|-|-|-|-|-|-|-|-|-|
> |Cache #0|1|1|1|1|1|1|5|5|5|5|4|4|
> |Cache #1||2|2|2|2|2|2|1|1|1|1|5|
> |Cache #2|||3|3|3|3|3|3|2|2|2|2|
> |Cache #3||||4|4|4|4|4|4|3|3|3|
> |Cache命中?|否|否|否|否|是|是|否|否|否|否|否|否|
> |Cache替换?|否|否|否|否|否|否|是|是|是|是|是|是|

先进先出算法 -- 实现简单, 最开始按照#0#1#2#3放入Cache, 之后轮流替换#0#1#2#3, FIFO依然没有考虑局部性原理, 最先被调入Cache的块也有可能是被频繁访问的

抖动现象: 频繁的换入换出现象(刚被替换的块很快又被调入)

### 近期最少使用算法(LRU)

近期最少使用算法(LRU, Least Recently Used) -- 为每一个Cache块设置一个"计数器", 用于记录每个Cache块已经有多久没有被访问了. 当Cache满后替换"计数器"最大的

> 设总共有4个Cache块, 初始整个Cache为空. 采用全相联映射, 依次访问主存块1,2,3,4,1,2,5,1,2,3,4,5
> |访问主存块|1|2|3|4|1|2|5|1|2|3|4|5|
> |-|-|-|-|-|-|-|-|-|-|-|-|-|
> |Cache #0|1|1|1|1|1|1|1|1|1|1|1|5|
> |Cache #1||2|2|2|2|2|2|2|2|2|2|2|
> |Cache #2|||3|3|3|3|5|5|5|5|4|4|
> |Cache #3||||4|4|4|4|4|4|3|3|3|
> |Cache命中?|否|否|否|否|是|是|否|是|是|否|否|否|
> |Cache替换?|否|否|否|否|否|否|是|否|否|是|是|是|

1. 命中时, 所命中的行的计数器清零, 比其低的计数器+1, 其余不变;
2. 未命中且还有空闲行时, 新装入的行的计数器置0, 其余非空闲行全加1;
3. 未命中且无空闲行时, 计数值最大的行的信息块被淘汰, 新装行的块的计数器置0, 其余全加1

Cache块的总数=2^n, 则计数器只需要n位. 且Cache装满后所有计数器的值一定不重复

LRU算法 -- 基于"局部性原理", 近期被访问过的主存块, 在不久的将来也很有可能被再次访问, 因此淘汰最久没访问过的块是合理的. LRU算法的实际效果优秀, Cache命中率高. 若被频繁访问的主存块数量>Cache行的数量, 则有可能发生抖动, 如:1,2,3,4,5,1,2,3,4,5,1,2...

### 最不经常使用算法(LFU)

最不经常使用算法(LFU, Least Frequently Used) -- 为每一个Cache块设置一个"计数器", 用于记录每个Cache块被访问过几次. 当Cache满后替换"计数器"最小的

> 设总共有4个Cache块, 初始整个Cache为空. 采用全相联映射, 依次访问主存块1,2,3,4,1,2,5,1,2,3,4,5
> |访问主存块|1|2|3|4|1|2|5|1|2|3|4|5|
> |-|-|-|-|-|-|-|-|-|-|-|-|-|
> |Cache #0|1|1|1|1|1|1|1|1|1|1|1|1|
> |Cache #1||2|2|2|2|2|2|2|2|2|2|2|
> |Cache #2|||3|3|3|3|5|5|5|3|3|5|
> |Cache #3||||4|4|4|4|4|4|4|4|4|
> |Cache命中?|否|否|否|否|是|是|否|是|是|否|是|否|
> |Cache替换?|否|否|否|否|否|否|是|否|否|是|否|是|

新调入的块计数器=0, 之后每被访问一次计数器+1. 需要替换的时候, 选择计数器最小的一行

LFU算法 -- 曾经被经常访问的主存块在未来不一定会使用到(如: 微信视频聊天相关的块)并没有很好地遵循局部性原理, 因此实际运行效果不如LRU

## Cache写策略

### 写命中

#### 写回法(Write-back)

当CPU对Cache写命中时, 只修改Cache的内容, 而不立即写入主存, 只有当此块被换出时才写回主存. 可以增设一个标志位(脏位), 以反映此块是否被CPU修改过

减少了访问次数, 但有数据不一致的隐患

#### 全写法(Write-through)

当CPU对Cache写命中的时候, 必须把数据同时写入Cache和主存, 一般使用写缓冲(Write buffer)

访存次数增加, 速度变慢, 但更能保证数据一致性

使用写缓冲, CPU写的速度很快, 若写操作不频繁, 则效果很好. 若写操作很频繁, 可能会因为写缓冲饱和而发生阻塞. 写缓冲是一个FIFO队列, 写缓冲可以解决速度不匹配的问题.

![](https://img1.imgtp.com/2022/07/29/ugVNN3P4.png)

### 写不命中

#### 写分配法(Write-allocate)

当CPU对Cache写不命中的时候, 把主存中的块调入Cache, 在Cache中修改, 通常搭配写回法使用.

#### 非写分配法(Not-write-allocate)

当CPU对Cache写不命中时只写入主存, 不调入Cache, 搭配全写法使用

### 多级Cache

现代计算机多采用多级Cache
<br> 离CPU越近的速度越快, 容量越小
<br> 离CPU越远的速度越慢, 容量越大

各级Cache之间通常采用"全写法"+"非写分配法"
<br> Cache-主存之间常采用"写回法"+"写分配法"

![](https://img1.imgtp.com/2022/07/29/gNT9Y3f3.png)

## 页式存储器

### 页式存储

一个程序(进程)在逻辑上被分为若干个大小相等的"页面", "页面"的大小与"块"的大小相同. 每个页面可以离散地放入不同的主存块中

### 虚地址vs实地址

- 逻辑地址(虚地址): 程序员视角看到的地址
- 物理地址(实地址): 实际在主存中的地址

> 假设某程序4KB, 操作系统将该程序分为4页, 每页1KB, 要实现取变量x至ACC寄存器
> <br> 机器指令: 000001 001000000011(操作码+地址码, 使用逻辑地址)
> <br> 程序员视角: 整个程序一共4KB=2^12B, 地址范围: 000000000000~111111111111
> <br> 变量x的逻辑地址: 001000000011, 则应该被划分在0号页面中(逻辑页号若干位, 页内地址10位)
> <br> 主存的物理地址一共22位(主存块号12位, 块内地址10位), 变量x的物理地址: 000000000010 10000000011

### 页表: 逻辑页号->主存块号

> |逻辑页号|主存块号|
> |-|-|
> |#0|2|
> |#1|4094|
> |#2|0|
> |#3|4095|
> 
> 变量x的逻辑地址: 001000000011 变量x的物理地址: 000000000010 1000000011

CPU执行的机器指令中, 使用的是"逻辑地址", 因此需要通过"页表"将逻辑地址转化为"物理地址", 页表存储在主存里
<br> 页表的作用: 记录了每个逻辑页面存放在哪个主存块中

### 地址变换过程

![](https://img1.imgtp.com/2022/07/29/MKWGShxp.png)

### 地址变换过程(增加TLB)

![](https://img1.imgtp.com/2022/07/29/XykKUOMO.png)

注意TLB和Cache的区别: 快表中存储的是页表项的副本; Cache中存储的是主存块的副本

为什么快表很快? -- 因为快表是一种SRAM而内存是一种DRAM, 此外, 快表是一种"相联存储器", 可以按照内容寻访

### 访问过程

![](https://img1.imgtp.com/2022/07/29/btRHOvhe.svg)
